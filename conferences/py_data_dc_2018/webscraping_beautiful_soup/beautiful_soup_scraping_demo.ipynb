{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Code Demo of Web Scraping w/ Beautiful Soup\n",
    "- By: Monica Puerto \n",
    "- (slight edits throughout and some commentary by Paul Jeffries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "#import this package if you have encoding errors\n",
    "# import sys\n",
    "# sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# extract the HTML into text \n",
    "r = requests.get('https://www.imdb.com/title/tt0071853/')\n",
    "# print the response received\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the unparsed text itself\n",
    "# we won't print this because it would be super slow\n",
    "r_unparsed = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10545992851257324\n"
     ]
    }
   ],
   "source": [
    "# we'll use the time package to figure out how long the query took\n",
    "# and we'll use the beautiful soup package to scrape the unparsed info from the website\n",
    "\n",
    "# start the clock\n",
    "start = time.time()\n",
    "b = BeautifulSoup(r_unparsed,'lxml')\n",
    "# stop the clock\n",
    "end = time.time()\n",
    "# as we can see, it took less than a second\n",
    "print(end - start)\n",
    "# had we used 'html-parser' instead of 'lxml' it would have taken longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python and the Holy Grail (1975) - IMDb\n",
      "Monty Python and the Holy GrailÂ (1975) \n",
      "[<title>Monty Python and the Holy Grail (1975) - IMDb</title>, <title>TryIMDbProFree</title>]\n"
     ]
    }
   ],
   "source": [
    "# extract the title and save it into a variable\n",
    "# there are 2 methods to find the title of a page when it comes to beautiful soup\n",
    "# you can use some specific methods from Beautiful Soup, or follow the tree\n",
    "title = b.title.text\n",
    "print(title)\n",
    "print(b.find('h1').text)\n",
    "\n",
    "# if there was more than 1 title, you would have to use the method below\n",
    "title = b.find_all('title')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Arthur and his Knights of the Round Table embark on a surreal, low-budget search for the Holy Grail, encountering many, very silly obstacles.\n",
      "PG\n"
     ]
    }
   ],
   "source": [
    "# NB: the way that you would find most of these tags--i.e. \"summary_text\"--is via inspect element\n",
    "# this can be done in Chrome, firefox, etc.\n",
    "\n",
    "# extract the description of the movie and save it into a variable\n",
    "desc = b.find('div','summary_text').text.strip()\n",
    "print(desc)\n",
    "\n",
    "# extract the Rating eg: R and save into a variable\n",
    "print(b.find('div','subtext').text.strip()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Graham Chapman', 'John Cleese', 'Eric Idle', 'Terry Gilliam']\n"
     ]
    }
   ],
   "source": [
    "# here's another method for getting at the various sub-components like the rating, the list of actors, etc.\n",
    "rating = json.loads(b.find('script', type='application/ld+json').text)['contentRating']\n",
    "\n",
    "## extract the actors \n",
    "actors = json.loads(b.find('script', type='application/ld+json').text)['actor']\n",
    "\n",
    "actors_list = []\n",
    "\n",
    "for actor in actors:\n",
    "\tactors_list.append(actor[u'name'])\n",
    "\n",
    "# and now that we've iterated through the actors, let's print the list of actors we returned\n",
    "print(actors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Graham Chapman', 'John Cleese', 'Eric Idle', 'Terry Gilliam']\n",
      "['Terry Gilliam', 'Terry Jones']\n"
     ]
    }
   ],
   "source": [
    "# now we can create some functions to take in an unparsed beautiful soup object and return lists of actors and directors\n",
    "def actors(x):\n",
    "\tactors_list = []\n",
    "\tactors = json.loads(x.find('script', type='application/ld+json').text)['actor']\n",
    "\tfor actor in actors:\n",
    "\t\tactors_list.append(str(actor['name']))\n",
    "\treturn actors_list\n",
    "\n",
    "def directors(x):\n",
    "\tdirectors = json.loads(x.find('script', type='application/ld+json').text)['director']\n",
    "\tdirectors_list = []\n",
    "\tfor director in directors:\n",
    "\t\tdirectors_list.append(str(director['name']))\n",
    "\treturn directors_list\n",
    "\n",
    "print(actors(b))\n",
    "print(directors(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tt6306064': {'title': 'Adrift (2018) - IMDb', 'desc': \"A true story of survival, as a young couple's chance encounter leads them first to love, and then on the adventure of a lifetime as they face one of the most catastrophic hurricanes in recorded history.\", 'rating': 'PG-13', 'actors': ['Shailene Woodley', 'Sam Claflin', 'Jeffrey Thomas', 'Elizabeth Hawthorne']}}\n"
     ]
    }
   ],
   "source": [
    "# create a function that extracts this information of any IMDB movie of your choosing into the form of a dictionary \n",
    "\n",
    "def movie_info(id):\n",
    "\tr = requests.get('https://www.imdb.com/title/{0}/'.format(id))\n",
    "\tb = BeautifulSoup(r.text,'lxml')\n",
    "\tmovie_dict = {}\n",
    "\tmovie_dict[id] = {}\n",
    "\tmovie_dict[id]['title'] = b.title.text\n",
    "\tmovie_dict[id]['desc'] = b.find('div','summary_text').text.strip()\n",
    "\tmovie_dict[id]['rating'] = json.loads(b.find('script', type='application/ld+json').text)['contentRating']\n",
    "\tmovie_dict[id]['actors'] = actors(b)\n",
    "\treturn movie_dict\n",
    "\n",
    "Adrift = movie_info('tt6306064')\n",
    "print(Adrift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
