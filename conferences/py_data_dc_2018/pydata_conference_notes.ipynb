{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData DC Conference\n",
    "Friday November 16th, 2018\n",
    "\n",
    "Hi there! The notes below are my scribblings from my time at the 2018 DC PyData Conference, hosted at Capital One's HQ in McLean, VA. There were 4 timeslots for sessions peppered throughout the day, with 2 sessions from which to choose during each timeslot. As such, I was only able to attend 4/8 total sessions. For the complete schedule (so you can see what I missed) check out the [full schedule for the day here](https://pydata.org/dc2018/schedule/). \n",
    "\n",
    "I recommend reading this write-up about the conference once-through and then jumping to the different notebooks, files, and folders I mention throughout for more information about particular sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Recreating, Understanding, and Visualizing FiveThirtyEight's Forecast \n",
    "Presenters: Joseph Nelson, Matt Brems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "The code and associated info for the talk can be found [on Joseph's GitHub here.](https://github.com/josephofiowa/pydata-dc-2018)\n",
    "\n",
    "How do you forecast (generally)?\n",
    "\n",
    "1. Brainstorm causal variables.\n",
    "    - This is informed by domain knowledge.\n",
    "2. Break the problem into achievable bits\n",
    "    - 538 example: 1 big model that includes polling, but polling is a function of another model (the pollster ratings).\n",
    "3. Collect, clean data\n",
    "4. Test \n",
    "    - Build a model and see how it does.\n",
    "5. Accept that \"done\" is better than perfect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building a recommender system from scratch \n",
    "Presenter: Jill Cates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "The code for the talk can be found [on Jill's GitHub here.](https://github.com/topspinj/pydata-workshop)\n",
    "\n",
    "1. Sometimes less is more.\n",
    "    - Stanford / Columbia study showing that fewer choices of samples of jam led to more conversions.\n",
    "2. Two types of recommender systems:\n",
    "    - Collaborative Filtering:\n",
    "        - Makes use of user feedback (either explicit or implicit)\n",
    "        - Using a user feedback score (dwell time, frequency of interactions)\n",
    "    - Content-based Filtering:\n",
    "        - Kinda like hedonic regression. Includes user features and item features (gender, age, etc.)\n",
    "\n",
    "Turn to the Jupyter notebook that have included here for the rest of the content and notes. It is almost identical to the version presented by Jill the day of the presentation, with a few small changes / additions to handle for an error that came up during the live code walkthrough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Cleaning and Tidying Data in Pandas\n",
    "Presenter: Daniel Chen \n",
    "    \n",
    "### Notes\n",
    "\n",
    "This talk did not come with a pre-prepared notebook, but there was a notes handout [which can be found here.](https://pydata.org/dc2018/schedule/presentation/37/) The GitHub repo that contains all of the [initial data and code can be found here](https://github.com/chendaniely/pydatadc_2018-tidy). \n",
    "\n",
    "Check out the Jupyter Notebook that I used to follow along with Daniel's live coding here, which includes some call-outs  for useful functions or best practices when using pandas that might not be immediately intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Web Scraping with Beautiful Soup\n",
    "Presenter: Monica Puerto \n",
    "    \n",
    "### Notes\n",
    "\n",
    "The code for the talk as well as her full presentation can be [found on Monica's GitHub here](https://github.com/monipip3/wwcdc/tree/master/webscraping). The code on her GitHub is located in 2 .py files, but during her live presentation, I coded up a jupyter notebook equivalent, which can be found here for anyone interested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
